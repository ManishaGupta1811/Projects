{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Automated Fuzzy Matching to Merge Similar Customer**\n",
        "\n",
        "This code is processing a CSV file (POTENTIAL CUSTOMERS PDT DATA.csv) that contains customer data and aims to merge rows where customer names are similar, based on fuzzy matching."
      ],
      "metadata": {
        "id": "hx-ivOcylqVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing fuzzy wuzzy"
      ],
      "metadata": {
        "id": "NXhOqkGumRUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSV_leYnvqeV",
        "outputId": "5a1d8b93-9b4f-4fde-c988-bf55de7f2975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install fuzzywuzzy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing levenshtein"
      ],
      "metadata": {
        "id": "D2YR6U2pmln0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-Levenshtein\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSzor61IwNhX",
        "outputId": "625ff386-95bc-41ff-eda5-f69fbf9db377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eufyLjEFFwrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:** To consolidate customer data by merging entries with similar customer names, effectively cleaning the dataset.\n",
        "\n",
        "**Methodology:**\n",
        "\n",
        "1. Uses fuzzy string matching to identify customer names that are similar\n",
        "(accounting for typos or variations).\n",
        "\n",
        "2. Merges the 'ASSESS VAL' by summing them up for similar customers.\n",
        "3. Concatenates 'HSN DESC' descriptions for a comprehensive overview.\n",
        "**Outcome:** A cleaned and consolidated dataset where each unique customer (after accounting for name variations) has a single entry, with their assessment values summed and descriptions combined.\n",
        "\n",
        "**Note**: *the data was primarily cleaned and filtered using power query to set time frames, geographical locations.*"
      ],
      "metadata": {
        "id": "WFbA-4SdmzmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# Read the CSV file\n",
        "filename = \"/content/POTENTIAL CUSTOMERS PDT DATA.csv\"\n",
        "df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
        "\n",
        "# Handle duplicate columns with different names\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Convert 'CUSTOMER' column to strings\n",
        "df['CUSTOMER'] = df['CUSTOMER'].astype(str)\n",
        "\n",
        "# Define a function to merge similar customer names\n",
        "def merge_similar_names(df):\n",
        "    # Dictionary to store indices of rows with similar names\n",
        "    similar_names_dict = {}\n",
        "\n",
        "    # Iterate over each row\n",
        "    for i, row in df.iterrows():\n",
        "        # Get the customer name from the current row\n",
        "        name = row['CUSTOMER']\n",
        "\n",
        "        # Find the most similar name in the dictionary\n",
        "        similar_name_tuple = process.extractOne(name, similar_names_dict.keys(), scorer=fuzz.token_sort_ratio)\n",
        "\n",
        "        # Check if a similar name was found\n",
        "        if similar_name_tuple is not None:\n",
        "            similar_name, score = similar_name_tuple\n",
        "\n",
        "            # If the similarity score is above the threshold, merge the data\n",
        "            if score > 80:\n",
        "                # Add the current row index to the list of indices for the similar name\n",
        "                similar_names_dict[similar_name].append(i)\n",
        "            else:\n",
        "                # Add a new entry in the dictionary for this name\n",
        "                similar_names_dict[name] = [i]\n",
        "        else:\n",
        "            # Add a new entry in the dictionary for this name\n",
        "            similar_names_dict[name] = [i]\n",
        "\n",
        "    # Merge rows with similar names\n",
        "    merged_rows = []\n",
        "    for similar_name, indices in similar_names_dict.items():\n",
        "        if len(indices) > 1:\n",
        "            # Merge rows with similar names\n",
        "            merged_row = df.iloc[indices[0]].copy()\n",
        "            for index in indices[1:]:\n",
        "                merged_row['ASSESS VAL'] += df.iloc[index]['ASSESS VAL']\n",
        "                # Convert 'HSN DESC' values to string before concatenating\n",
        "                merged_row['HSN DESC'] = str(merged_row['HSN DESC']) + ' ' + str(df.iloc[index]['HSN DESC'])\n",
        "            merged_rows.append(merged_row)\n",
        "        else:\n",
        "            # If only one row, append as is\n",
        "            merged_rows.append(df.iloc[indices[0]])\n",
        "\n",
        "    # Create a new DataFrame with merged rows\n",
        "    merged_df = pd.DataFrame(merged_rows)\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Merge similar names\n",
        "merged_df = merge_similar_names(df)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "merged_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Export the result in a new CSV file\n",
        "merged_df.to_csv(\"result.csv\", index=False)\n",
        "\n",
        "print(\"Merging completed. Check 'result.csv' for the merged data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an72LmNN5JcO",
        "outputId": "de57c309-4815-498f-99d1-2c8f2a5fb27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging completed. Check 'result.csv' for the merged data.\n"
          ]
        }
      ]
    }
  ]
}